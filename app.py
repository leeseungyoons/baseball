import streamlit as st
import re
from sentiment_model import SentimentAnalyzer
from keyword_extractor import KeywordExtractor
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import seaborn as sns
from collections import Counter
from wordcloud import WordCloud

# ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
sa = SentimentAnalyzer()
ke = KeywordExtractor()

st.title("âš¾ ìŠ¤í¬ì¸  ê¸°ì‚¬ ê°ì • ë¶„ì„ê¸°")

uploaded_file = st.file_uploader("ğŸ“° ë‰´ìŠ¤ë‚˜ ì¤‘ê³„ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš” (.txt)", type="txt")

if uploaded_file is not None:
    text = uploaded_file.read().decode("utf-8")
    articles = re.split(r'(?:\n\s*){5,}', text.strip())  # 5ì¤„ ì´ìƒ ë¹ˆì¤„ ê¸°ì¤€ ë¶„ë¦¬

    sentiment_counts = Counter({"ê¸ì •": 0, "ë¶€ì •": 0})
    all_keywords = Counter()
    label_map = {"Positive": "ê¸ì •", "Negative": "ë¶€ì •"}

    # âœ… í™•ì¥ëœ í‚¤ì›Œë“œ
    positive_words = [
        "ìŠ¹ë¦¬", "ëŒ€ìŠ¹", "ì—­ì „ìŠ¹", "í™ˆëŸ°", "í™œì•½", "ë§¹íƒ€", "ê²°ìŠ¹íƒ€", "ê·¹ì ì¸", "ëë‚´ê¸°", "ë¬´ì‹¤ì ",
        "ì´ê¸°ë©°", "ì™„ë´‰", "4ì—°ìŠ¹", "5ì—°ìŠ¹", "í˜¸íˆ¬", "ê¸°ì„¸", "ëˆˆë¶€ì‹ ", "ì—°ìŠ¹", "ì—­ì „ê·¹", "ì¾Œì¡°",
        "ë“œë¼ë§ˆí‹±", "MVP", "ì„ ë°œìŠ¹", "ê¸°ë¡ ê²½ì‹ ", "ë†€ë¼ìš´", "ì™„ë²½í•œ", "ì••ë„ì ", "4íƒ€ìˆ˜ 4ì•ˆíƒ€"
    ]
    negative_words = [
        "íŒ¨ë°°", "ë³‘ì‚´íƒ€", "ì‹¤ì±…", "ë†“ì³¤ë‹¤", "ë¬´ë“ì ", "íŒ¨ì „", "ë¬´ìŠ¹ë¶€", "ë¬´ì‚°", "ë¶€ì§„", "ì—­ì „íŒ¨",
        "ë¶€ìƒ", "ì´íƒˆ", "ë¶ˆì•ˆ", "í˜¹ì‚¬", "ë¶€ì§„í•œ íë¦„", "ê¸°íšŒ ë†“ì³¤ë‹¤", "íƒˆë½", "ê²°ì¥", "í‡´ì¥"
    ]

    st.subheader("ğŸ“„ ê¸°ì‚¬ ë¶„ì„ ê²°ê³¼")

    for idx, article in enumerate(articles):
        st.markdown(f"### ğŸ“° ê¸°ì‚¬ #{idx+1}")
        st.text(article)

        # ê°ì • ë¶„ì„ ì‹¤í–‰
        try:
            orig_label, pos_score, neg_score = sa.predict(article)
        except Exception as e:
            st.error(f"ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            continue

        # ê°ì • ë³´ì • ë¡œì§
        has_positive = any(word in article for word in positive_words)
        has_negative = any(word in article for word in negative_words)
        label = orig_label  # ê¸°ë³¸ ëª¨ë¸ ê²°ê³¼
        translated_label = label_map.get(label, label)

        if has_negative and not has_positive:
            label = "Negative"
            translated_label = "ë¶€ì •"
            st.caption("âš ï¸ ë¶€ì • í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆì–´ ê°ì • ê²°ê³¼ê°€ ë³´ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
        elif has_positive and not has_negative:
            label = "Positive"
            translated_label = "ê¸ì •"
            st.caption("âœ… ê¸ì • í‚¤ì›Œë“œë§Œ ìˆì–´ ê°ì • ê²°ê³¼ê°€ ë³´ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
        elif has_positive and has_negative:
            st.caption("â„¹ï¸ ê¸ì •/ë¶€ì • í‚¤ì›Œë“œê°€ ëª¨ë‘ ìˆì–´ ëª¨ë¸ ì›ë˜ ê²°ê³¼ ìœ ì§€ë¨.")

        # ê°ì • ì¶œë ¥
        st.write(f"**ê°ì • ë¶„ì„ ê²°ê³¼:** {translated_label}")
        st.write(f"ê¸ì •: {pos_score:.4f} / ë¶€ì •: {neg_score:.4f}")
        st.progress(pos_score)
        st.caption("âš ï¸ ê°ì • ë¶„ì„ì€ ì¼ë°˜ í…ìŠ¤íŠ¸ ê¸°ë°˜ì´ë©°, ìŠ¤í¬ì¸  ê¸°ì‚¬ì—ì„œëŠ” ì‹¤ì œ ë§¥ë½ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # ì¹´ìš´íŠ¸ ì €ì¥
        sentiment_counts[translated_label] += 1

        # í‚¤ì›Œë“œ ì¶”ì¶œ & ëˆ„ì 
        keywords = ke.extract(article)

        if keywords:
            all_keywords.update(keywords)
            st.write("**Top Keywords:**", ", ".join(keywords.keys()))
        else:
            st.write("â— í‚¤ì›Œë“œ ì—†ìŒ")


        st.markdown("---")

    st.info("â„¹ï¸ ì—¬ëŸ¬ ê¸°ì‚¬ë¥¼ ë„£ìœ¼ë ¤ë©´ ê¸°ì‚¬ ì‚¬ì´ì— **ë¹ˆ ì¤„ 5ì¹¸ ì´ìƒ** (Enter 5ë²ˆ)ì„ ë„£ì–´ì£¼ì„¸ìš”!")

    # âœ… í•œê¸€ í°íŠ¸ ì„¤ì •
    font_path = "NanumGothic.ttf"
    font_prop = fm.FontProperties(fname=font_path)

    # ğŸ“Š ê°ì • ìš”ì•½ ê·¸ë˜í”„
    st.subheader("ğŸ“Š ê°ì • ë¶„ì„ ìš”ì•½")
    labels = ["ê¸ì •", "ë¶€ì •"]
    values = [sentiment_counts["ê¸ì •"], sentiment_counts["ë¶€ì •"]]
    colors = ["#4da6ff", "#ff6666"]

    sns.set_style("whitegrid")
    fig, ax = plt.subplots(figsize=(6, 4))
    bars = ax.bar(labels, values, color=colors)

    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width() / 2, height + 0.1, f"{int(height)}",
                ha='center', va='bottom', fontsize=12, fontweight='bold', fontproperties=font_prop)

    ax.set_xticklabels(labels, fontproperties=font_prop)
    ax.set_ylim(0, max(values) + 1)
    ax.set_ylabel("ê°ì •ë³„ ê¸°ì‚¬ ê°œìˆ˜", fontsize=11, fontproperties=font_prop)
    ax.set_xlabel("ê°ì • ë¶„ë¥˜", fontsize=11, fontproperties=font_prop)
    ax.set_title("ê°ì • ë¶„ì„ ê²°ê³¼ ë¶„í¬", fontsize=14, fontweight='bold', fontproperties=font_prop)

    st.pyplot(fig)

    # â˜ï¸ ì›Œë“œí´ë¼ìš°ë“œ
    st.subheader("â˜ï¸ í‚¤ì›Œë“œ ì›Œë“œ í´ë¼ìš°ë“œ")

    
    
    if all_keywords:
        wc = WordCloud(
            font_path=font_path,
            background_color="white",
            width=800,
            height=400
        )

        freq_dict = dict((k, int(v)) for k, v in all_keywords.items() if isinstance(v, (int, float)) and v > 0)

        if freq_dict:
        
            wc.generate_from_frequencies(dict(all_keywords))
            fig2, ax2 = plt.subplots(figsize=(10, 5))
            ax2.imshow(wc, interpolation="bilinear")
            ax2.axis("off")
            st.pyplot(fig2)
        else:
            st.warning("â— í‚¤ì›Œë“œê°€ ë¶€ì¡±í•´ ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.warning("â— í‚¤ì›Œë“œê°€ ë¶€ì¡±í•´ ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
